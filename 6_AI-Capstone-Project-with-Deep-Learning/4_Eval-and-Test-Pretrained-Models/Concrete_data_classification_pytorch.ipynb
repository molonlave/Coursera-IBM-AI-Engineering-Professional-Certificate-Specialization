{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-02 08:18:24--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2598656062 (2.4G) [application/zip]\n",
      "Saving to: ‘Positive_tensors.zip’\n",
      "\n",
      "100%[====================================>] 2,598,656,062 38.3MB/s   in 1m 43s \n",
      "\n",
      "2020-03-02 08:20:08 (24.0 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-02 08:21:32--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2111408108 (2.0G) [application/zip]\n",
      "Saving to: ‘Negative_tensors.zip’\n",
      "\n",
      "100%[====================================>] 2,111,408,108 30.7MB/s   in 77s    \n",
      "\n",
      "2020-03-02 08:22:50 (26.0 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will install torchvision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 20.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.4.0 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 30kB/s s eta 0:00:01█▉                             | 67.7MB 66.4MB/s eta 0:00:11��████▋                       | 201.8MB 68.3MB/s eta 0:00:09��        | 551.9MB 68.6MB/s eta 0:00:03███████████████████▌     | 623.0MB 58.4MB/s eta 0:00:03   | 660.2MB 165kB/s eta 0:09:24��████████████████████▌  | 695.0MB 165kB/s eta 0:05:54�██▊| 746.4MB 75.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.15.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe09bbd5f90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/dsxuser/work\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/dsxuser/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d237a34d3d40b7a9297ce9eb356ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will train your, model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=100)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "start_time = time.time()\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # traning phase\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        model.train() \n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        yhat = model(x)\n",
    "        # calculate loss \n",
    "        loss = criterion(yhat, y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.data.item())\n",
    "\n",
    "    # validating phase\n",
    "    correct=0\n",
    "    for x_test, y_test in validation_dataloader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        yhat = model(x_test)\n",
    "        #find max \n",
    "        _, yhat = yhat.max(-1)\n",
    "        #Calculate misclassified  samples in mini-batch\n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct += (yhat == y_test).sum().item()\n",
    "    accuracy_list.append(correct / N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 30\n",
    "# counter = 0\n",
    "# while True:\n",
    "#     print(idx)\n",
    "#     y = validation_dataset[idx][1]\n",
    "#     x = validation_dataset[idx][0]\n",
    "#     yhat = model(torch.unsqueeze(x, 0))\n",
    "#     _, yhat = yhat.max(-1)\n",
    "#     if yhat != y:\n",
    "#         img = np.moveaxis(x.numpy(), 0, 2)\n",
    "#         _min, _max = img.min(), img.max()\n",
    "#         img = (img - _min) / (_max - _min)\n",
    "#         plt.imshow(img)\n",
    "#         plt.tile(f\"sample{idx} predicted value:{yhat} actual value:{y}\")\n",
    "#         plt.show()\n",
    "#         counter += 1\n",
    "#     if counter == 4:\n",
    "#         break\n",
    "#     idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 38 predicted value: 0 actual value: 1 \n",
      "sample 65 predicted value: 1 actual value: 0 \n",
      "sample 92 predicted value: 0 actual value: 1 \n",
      "sample 556 predicted value: 0 actual value: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"sample 38 predicted value: 0 actual value: 1 \\n\"\n",
    "      \"sample 65 predicted value: 1 actual value: 0 \\n\"\n",
    "      \"sample 92 predicted value: 0 actual value: 1 \\n\"\n",
    "      \"sample 556 predicted value: 0 actual value: 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
